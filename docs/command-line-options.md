# ğŸ”— String Pipeline - Command Line Interface

_NOTE: what follows has mostly been assembled using AI as an experiment and as a basis for further improvements._

A comprehensive CLI tool for powerful string transformations with flexible input/output options and advanced debugging capabilities.

## ğŸ“‹ Table of Contents

- [ğŸ—ï¸ Basic Usage](#ï¸-basic-usage)
- [ğŸ“¥ Input Sources](#-input-sources)
- [ğŸ“ Template Input](#-template-input)
- [ğŸ“¤ Output Control](#-output-control)
- [ğŸ› Debug & Validation](#-debug--validation)
- [ğŸ“š Help & Information](#-help--information)
- [ğŸ¯ Common Usage Patterns](#-common-usage-patterns)
- [ğŸ”„ Advanced Workflows](#-advanced-workflows)
- [âš ï¸ Error Handling](#ï¸-error-handling)
- [ğŸ’¡ Best Practices](#-best-practices)
- [âš¡ Performance & Benchmarking](#-performance--benchmarking)
- [ğŸ”§ Troubleshooting](#-troubleshooting)

## ğŸ—ï¸ Basic Usage

### Command Structure

```bash
string-pipeline [OPTIONS] [TEMPLATE] [INPUT]
```

| Component | Required | Description |
|-----------|----------|-------------|
| `TEMPLATE` | âœ…* | Template string to apply |
| `INPUT` | âŒ | Input string to process |
| `OPTIONS` | âŒ | Configuration flags and parameters |

> ğŸ’¡ **Note:** `TEMPLATE` is optional only when using `--template-file` option.

### ğŸ”„ Input Priority Order

The CLI processes input sources in this priority order:

1. **ğŸ¯ Command Line Argument** - `INPUT` parameter
2. **ğŸ“ File Input** - `--input-file` option
3. **âŒ¨ï¸ Standard Input** - Default fallback (pipes, redirects)

**Quick Examples:**

```bash
# ğŸ¯ Direct arguments
string-pipeline '{upper}' 'hello world'
# Output: HELLO WORLD

# âŒ¨ï¸ From stdin (pipe)
echo "hello world" | string-pipeline '{upper}'
# Output: HELLO WORLD

# ğŸ“ From file
echo "hello world" > input.txt
string-pipeline '{upper}' -f input.txt
# Output: HELLO WORLD
```

## ğŸ“¥ Input Sources

### ğŸŒŠ Standard Input (Stdin)

The most flexible input method - works with pipes, redirects, and interactive input.

| Method | Syntax | Description | Use Case |
|--------|--------|-------------|----------|
| **ğŸ”— Pipe** | `command \| string-pipeline` | Chain with other tools | Data processing pipelines |
| **ğŸ“‚ Redirect** | `string-pipeline < file.txt` | Read from file | Batch file processing |
| **ğŸ“ Heredoc** | `string-pipeline <<< "text"` | Inline text input | Quick testing |
| **âŒ¨ï¸ Interactive** | `string-pipeline '{template}'` | Type input manually | Development/testing |

**Real-world Examples:**

```bash
# ğŸ”— Process command output
echo "apple banana cherry" | string-pipeline '{split: :..|map:{upper}}'

# ğŸ“‚ Process log files
echo -e "ERROR: failed\nINFO: success" | string-pipeline '{split:\n:..|filter:ERROR}'

# ğŸ“ Quick data transformation
string-pipeline '{split:,:..|map:{upper}|join:-}' <<< "apple,banana,cherry"
# Output: APPLE-BANANA-CHERRY

# âŒ¨ï¸ Interactive development
string-pipeline '{split: :..|map:{upper}}'
# Type: hello world test
# Output: HELLO,WORLD,TEST
```

### ğŸ¯ Command Line Arguments

Perfect for scripting and automation when input is known.

```bash
# âœ¨ Simple transformation
string-pipeline '{upper}' "hello world"

# ğŸ”„ Complex processing
string-pipeline '{split:,:..|map:{trim|upper}|filter:^[A-Z]{3,}|sort}' "  apple  , banana , cat ,  elephant  "
# Output: APPLE,BANANA,ELEPHANT
```

### ğŸ“ File Input

Ideal for processing existing files and batch operations.

**Syntax:** `--input-file FILE` or `-f FILE`

```bash
# ğŸ“Š Process CSV data
echo "Name,Age,City\nJohn,30,NYC\nJane,25,LA" > data.csv
string-pipeline '{split:\n:..|slice:1..|map:{split:,:0|upper}}' -f data.csv
# Output: JOHN,JANE

# ğŸ“‹ Process log files
echo "2023-01-01 ERROR Failed\n2023-01-02 INFO Success" > app.log
string-pipeline '{split:\n:..|filter:ERROR|map:{regex_extract:\d{4}-\d{2}-\d{2}}}' -f app.log
# Output: 2023-01-01

# ğŸ§¹ Clean data files
string-pipeline '{split:\n:..|map:{trim}|filter:^.+$|unique}' -f messy_data.txt
```

## ğŸ“ Template Input

### ğŸ¯ Inline Templates

Default method - template provided as command argument.

```bash
# ğŸ”¤ Basic operations
string-pipeline '{upper}' 'hello world'
string-pipeline '{split:,:..|join:-}' 'a,b,c'

# ğŸ”§ Complex transformations
string-pipeline '{split: :..|map:{substring:0..1|upper}|join:}' 'hello world test'
# Output: HWT
```

### ğŸ“„ Template Files

Store complex templates in files for reuse and better organization.

**Syntax:** `--template-file FILE` or `-t FILE`

**Creating Template Files:**

```bash
# ğŸ“ Create reusable templates
echo '{split:,:..|map:{trim|upper}|sort|join: | }' > format_list.template
echo '{regex_extract:\d{4}-\d{2}-\d{2}}' > extract_date.template
echo '{split:\n:..|filter:ERROR|map:{regex_extract:\d{2}:\d{2}:\d{2}}}' > extract_error_times.template
```

**Using Template Files:**

```bash
# ğŸ“Š Format data consistently
string-pipeline -t format_list.template 'apple, banana, cherry'
# Output: APPLE | BANANA | CHERRY

# ğŸ“… Extract dates from logs
echo "2023-01-01 ERROR Failed" > app.log
string-pipeline -t extract_date.template -f app.log

# ğŸ”„ Combine template and input files
echo "apple,banana,cherry" > data.txt
string-pipeline -t format_list.template -f data.txt
```

**Template File Benefits:**

| Benefit | Description | Example Use Case |
|---------|-------------|------------------|
| **â™»ï¸ Reusability** | Use same template with different inputs | Standard data formatting |
| **ğŸ“– Readability** | Complex templates are easier to read | Multi-step transformations |
| **ğŸ”§ Maintainability** | Update logic in one place | Production data processing |
| **ğŸ“‹ Documentation** | Self-documenting with comments | Team workflows |

## ğŸ“¤ Output Control

### ğŸ¨ Output Formats

Control how results are presented with the `--output` or `-o` option.

| Format | Description | Best For | Example |
|--------|-------------|----------|---------|
| **ğŸ“„ `raw`** | Output as-is (default) | Single values, custom formatting | `A,B,C` |
| **ğŸ“‹ `lines`** | Split comma-separated into lines | Lists, easy reading | `A`<br/>`B`<br/>`C` |
| **ğŸ”— `json`** | JSON format | API integration, structured data | `["A","B","C"]` |

**Format Examples:**

```bash
# ğŸ“„ Raw format (default)
string-pipeline '{split:,:..|map:{upper}}' 'a,b,c'
# Output: A,B,C

# ğŸ“‹ Lines format - great for readability
string-pipeline -o lines '{split:,:..|map:{upper}}' 'a,b,c'
# Output:
# A
# B
# C

# ğŸ”— JSON format - perfect for APIs
string-pipeline -o json '{split:,:..|map:{upper}}' 'a,b,c'
# Output: ["A","B","C"]

# ğŸ”— JSON with single value
string-pipeline -o json '{upper}' 'hello'
# Output: "HELLO"
```

### ğŸ¤« Quiet Mode

Suppress debug output and validation messages with `--quiet` or `-q`.

```bash
# ğŸ”Š Normal debug mode (shows detailed step-by-step processing)
string-pipeline -d '{split:,:..|map:{upper}}' "hello,world"
# [Detailed debug output - see Debug System Guide for complete examples]
# HELLO,WORLD

# ğŸ¤« Quiet debug mode (result only)
string-pipeline -d -q '{split:,:..|map:{upper}}' 'a,b,c'
# A,B,C

# ğŸ¤« Quiet validation (silent success)
string-pipeline -q --validate '{split:,:..|upper}'
# (no output if template is valid)
```

## ğŸ› Debug & Validation

> ğŸ” **For comprehensive debugging coverage**, see the [ğŸ› Debug System Guide](debug-system.md) which provides in-depth documentation on advanced debugging techniques, performance analysis, error diagnosis, and real-world troubleshooting scenarios.

### ğŸ” Debug Mode

Enable step-by-step processing visualization.

**Syntax:** `--debug` or `-d`

**What Debug Mode Shows:**

- ğŸ¯ Initial input value
- ğŸ”„ Each operation being applied
- ğŸ“Š Intermediate results after each step
- ğŸ—ºï¸ Detailed map operation processing
- â±ï¸ Performance timing for each step
- ğŸ“Š Cache statistics
- âœ… Final output

**Debug Examples:**

```bash
# ğŸ” Basic debugging
string-pipeline -d '{split:,:..|map:{upper}}' 'hello,world'
# [Shows detailed step-by-step processing - see Debug System Guide]
# HELLO,WORLD

# ğŸ¤« Quiet debugging (result only)
string-pipeline -d -q '{split:,:..|map:{upper}}' 'hello,world'
# HELLO,WORLD
```

### âœ… Template Validation

Validate template syntax without processing data.

**Syntax:** `--validate`

```bash
# âœ… Valid template
string-pipeline --validate '{split:,:..|map:{upper}|join:-}'
# Template syntax is valid

# âŒ Invalid template
string-pipeline --validate '{split:,:..|invalid_op}'
# Error parsing template: Unknown operation: invalid_op

# ğŸ¤« Quiet validation (scripting)
if string-pipeline -q --validate '{template}'; then
    echo "Template is valid"
else
    echo "Template has errors"
fi
```

### ğŸ”„ Inline Debug vs CLI Debug

| Method | Syntax | When to Use |
|--------|--------|-------------|
| **ğŸ” Inline Debug** | `{!operations...}` | Template development, one-off debugging |
| **ğŸ› ï¸ CLI Debug** | `--debug` flag | Script debugging, systematic testing |
| **ğŸ¤« Quiet Debug** | `--debug --quiet` | Production debugging, clean output |

```bash
# ğŸ” Inline debug (template syntax)
string-pipeline '{!split:,:..|map:{upper}}' 'a,b,c'

# ğŸ› ï¸ CLI debug (flag)
string-pipeline --debug '{split:,:..|map:{upper}}' 'a,b,c'

# ğŸ¤« Combined: inline debug with quiet flag
string-pipeline -q '{!split:,:..|map:{upper}}' 'a,b,c'
# A,B,C (debug info suppressed by -q)
```

## ğŸ“š Help & Information

### ğŸ“– Getting Help

| Option | Description | Example |
|--------|-------------|---------|
| `--help`, `-h` | Show command help | `string-pipeline --help` |
| `--version`, `-V` | Show version info | `string-pipeline --version` |
| `--list-operations` | List all available operations | `string-pipeline --list-operations` |
| `--syntax-help` | Show template syntax guide | `string-pipeline --syntax-help` |

**Information Examples:**

```bash
# ğŸ“– Basic help
string-pipeline --help

# ğŸ·ï¸ Version information
string-pipeline --version
# string-pipeline 0.12.0

# ğŸ“‹ List all operations
string-pipeline --list-operations
# Available operations:
# split - Split text into parts using separator
# join - Combine list items with separator
# upper - Convert to uppercase
# lower - Convert to lowercase
# ... (all operations listed)

# ğŸ“ Syntax guide
string-pipeline --syntax-help
# Template Syntax Guide:
# Basic structure: {operation1|operation2|...}
# Debug mode: {!operation1|operation2|...}
# ... (detailed syntax examples)
```

## ğŸ¯ Common Usage Patterns

### ğŸ› ï¸ Development Workflow

**1. ğŸ§ª Template Development:**

```bash
# âœ… Start with validation
string-pipeline --validate '{split:,:..|map:{upper}}'

# ğŸ” Add debugging
string-pipeline -d '{split:,:..|map:{upper}}' 'test,data'

# ğŸ¤« Clean up output
string-pipeline -d -q '{split:,:..|map:{upper}}' 'test,data'

# ğŸ’¾ Save successful template
echo '{split:,:..|map:{upper}|join:-}' > uppercase_list.template
```

**2. ğŸ“Š Data Processing Pipeline:**

```bash
# ğŸ”„ Multi-step data processing
cat raw_data.csv | \
    string-pipeline '{split:\n:..|slice:1..|filter:^[^#]}' | \
    string-pipeline '{split:,:..|map:{trim}}' | \
    string-pipeline -o json '{split:\n:..|unique|sort}'
```

### ğŸ­ Production Usage

**1. ğŸ“‹ Batch File Processing:**

```bash
# ğŸ”„ Process multiple files
for file in data_*.txt; do
    echo "Processing $file..."
    string-pipeline -t transform.template -f "$file" > "processed_$file"
done
```

**2. ğŸ”— Integration with Other Tools:**

```bash
# ğŸ“Š Extract and analyze
grep "ERROR" app.log | \
    string-pipeline '{regex_extract:\d{4}-\d{2}-\d{2}}' | \
    sort | uniq -c | sort -nr

# ğŸ”„ Data transformation pipeline
echo '{"items":["apple,banana","cherry,date"]}' | \
    jq -r '.items[]' | \
    string-pipeline '{split:,:..|map:{trim|upper}|filter:^[A-Z]{3,}}' | \
    string-pipeline -o lines '{split:,:..|sort}'
```

## ğŸ”„ Advanced Workflows

### ğŸ§ª Template Testing

```bash
# ğŸ¯ Create test data
echo "apple,banana,cherry,date" > test_data.txt

# ğŸ” Test templates incrementally
string-pipeline '{split:,:..}' -f test_data.txt
string-pipeline '{split:,:..|map:{upper}}' -f test_data.txt
string-pipeline '{split:,:..|map:{upper}|sort}' -f test_data.txt
string-pipeline '{split:,:..|map:{upper}|sort|join: \| }' -f test_data.txt

# âœ… Final validation
string-pipeline --validate '{split:,:..|map:{upper}|sort|join: \| }'
```

### ğŸ”§ Complex Data Processing

```bash
# ğŸ“‹ Multi-format output generation
DATA="john.doe@company.com,jane.smith@example.org,bob.wilson@test.net"

# ğŸ“„ Raw format
string-pipeline '{split:,:..|map:{regex_extract:@(.+):1|upper}}' "$DATA"
# Output: COMPANY.COM,EXAMPLE.ORG,TEST.NET

# ğŸ“‹ Lines format
string-pipeline -o lines '{split:,:..|map:{regex_extract:@(.+):1|upper}}' "$DATA"
# Output:
# COMPANY.COM
# EXAMPLE.ORG
# TEST.NET

# ğŸ”— JSON format for APIs
string-pipeline -o json '{split:,:..|map:{regex_extract:@(.+):1|upper}}' "$DATA"
# Output: ["COMPANY.COM","EXAMPLE.ORG","TEST.NET"]
```

### ğŸ¨ Custom Formatting

```bash
# ğŸ“Š Create formatted reports
USERS="Alice,Bob,Charlie,Diana"

# ğŸ“‹ Bullet list
string-pipeline '{split:,:..|map:{prepend:â€¢ |append: âœ“}}' "$USERS"
# Output: â€¢ Alice âœ“,â€¢ Bob âœ“,â€¢ Charlie âœ“,â€¢ Diana âœ“

# ğŸ”¢ Numbered list
string-pipeline -o lines '{split:,:..|map:{prepend:1. }}' "$USERS" | \
    awk '{gsub(/1\./, NR"."); print}'
# Output:
# 1. Alice
# 2. Bob
# 3. Charlie
# 4. Diana

# ğŸ“Š Table format
string-pipeline '{split:,:..|map:{pad:15: :both}|join:\|}' "$USERS"
# Output: '     Alice     |      Bob      |   Charlie     |     Diana     '
```

## âš ï¸ Error Handling

### ğŸš¨ Exit Codes

| Code | Meaning | Description |
|------|---------|-------------|
| **0** | âœ… Success | Operation completed successfully |
| **1** | âŒ Error | Template parsing, I/O, or processing error |

### ğŸ” Common Error Types

#### ğŸ“ Template Errors

```bash
# âŒ Invalid operation
string-pipeline '{invalid_op}' 'input'
# Error parsing template: Unknown operation: invalid_op

# âŒ Syntax error
string-pipeline '{split:,}' 'input'  # Missing range
# Error parsing template: Expected range specification after ':'

# âŒ Unclosed template
string-pipeline '{split:,:.. ' 'input'
# Error parsing template: Expected '}'
```

#### ğŸ“ Input/Output Errors

```bash
# âŒ File not found
string-pipeline '{upper}' -f nonexistent.txt
# Error reading input file: Failed to read file 'nonexistent.txt': No such file or directory

# âŒ Template file missing
string-pipeline -t missing.template 'input'
# Error reading template file: Failed to read file 'missing.template': No such file or directory

# âŒ Input conflict
string-pipeline '{upper}' -f input.txt 'also_input'
# Error: Cannot specify both input argument and input file
```

#### ğŸ”§ Processing Errors

```bash
# âŒ Invalid regex
string-pipeline '{filter:[}' 'input'
# Error: Invalid regex pattern: missing closing bracket

# âŒ Invalid range
string-pipeline '{split:,:abc}' 'input'
# Error: Invalid range specification: 'abc'

# âŒ Operation type mismatch
string-pipeline '{join:-}' 'plain_string'
# Error: join operation can only be applied to lists
```

### ğŸ›¡ï¸ Error Prevention

**âœ… Best Practices:**

```bash
# 1. âœ… Validate templates first
string-pipeline --validate '{template}' && \
string-pipeline '{template}' 'input'

# 2. ğŸ” Use debug mode during development
string-pipeline -d '{template}' 'test_input'

# 3. ğŸ§ª Test with simple data first
string-pipeline '{complex_template}' 'a,b,c'

# 4. ğŸ“ Check file existence
[ -f input.txt ] && string-pipeline '{template}' -f input.txt

# 5. ğŸ”„ Handle errors in scripts
if ! string-pipeline '{template}' 'input' > output.txt; then
    echo "Processing failed" >&2
    exit 1
fi
```

## ğŸ’¡ Best Practices

### ğŸ¯ Template Development

#### âœ… Do's

1. **ğŸ§ª Start Simple and Build Up:**

```bash
# âœ… Incremental development
string-pipeline '{split:,:..}' 'a,b,c'                    # Test split
string-pipeline '{split:,:..|map:{upper}}' 'a,b,c'        # Add transformation
string-pipeline '{split:,:..|map:{upper}|sort}' 'c,a,b'   # Add sorting
```

1. **ğŸ” Use Debug Mode Liberally:**

```bash
# âœ… Debug complex templates
string-pipeline -d '{split:,:..|map:{trim|upper}|filter:^[A-Z]{3,}}' '  apple  , hi , banana  '
```

1. **ğŸ“ Organize Complex Templates:**

```bash
# âœ… Save reusable templates
echo '{split:,:..|map:{trim|upper}|sort|unique}' > clean_sort_list.template
string-pipeline -t clean_sort_list.template 'data'
```

1. **âœ… Validate Before Processing:**

```bash
# âœ… Safe template execution
string-pipeline --validate '{template}' && \
string-pipeline '{template}' -f large_file.txt
```

#### âŒ Don'ts

1. **âŒ Don't Skip Validation:**

```bash
# âŒ Risk processing large data with broken template
string-pipeline '{broken_template}' -f huge_file.txt

# âœ… Validate first
string-pipeline --validate '{template}' && \
string-pipeline '{template}' -f huge_file.txt
```

1. **âŒ Don't Ignore Debug Output:**

```bash
# âŒ Assuming template works without testing
string-pipeline '{complex_template}' 'production_data'

# âœ… Test and debug first
string-pipeline -d '{complex_template}' 'test_data'
```

### âš¡ Performance Optimization

1. **ğŸ¯ Filter Early:**

```bash
# âœ… Filter before expensive operations
'{split:,:..|filter:important|map:{complex_operation}}'

# âŒ Process everything then filter
'{split:,:..|map:{complex_operation}|filter:IMPORTANT}'
```

1. **ğŸ“ Use Specific Ranges:**

```bash
# âœ… Process only what you need
'{split:,:0..10|map:{upper}}'

# âŒ Process everything then slice
'{split:,:..|map:{upper}|slice:0..10}'
```

1. **ğŸ”„ Combine Operations:**

```bash
# âœ… Single map with multiple operations
'{split:,:..|map:{trim|upper|append:!}}'

# âŒ Multiple separate maps
'{split:,:..|map:{trim}|map:{upper}|map:{append:!}}'
```

### ğŸ­ Production Usage

1. **ğŸ”’ Error Handling:**

```bash
# âœ… Robust script with error handling
#!/bin/bash
set -euo pipefail

if ! string-pipeline --validate "${TEMPLATE}"; then
    echo "Invalid template" >&2
    exit 1
fi

if ! string-pipeline "${TEMPLATE}" -f "${INPUT_FILE}" > "${OUTPUT_FILE}"; then
    echo "Processing failed" >&2
    exit 1
fi
```

1. **ğŸ“Š Logging and Monitoring:**

```bash
# âœ… Production processing with logging
{
    echo "Starting processing at $(date)"
    time string-pipeline -t transform.template -f data.txt
    echo "Processing completed at $(date)"
} 2>&1 | tee process.log
```

## âš¡ Performance & Benchmarking

String Pipeline includes built-in performance measurement tools accessible via the CLI.

### ğŸ”¬ Built-in Benchmarking Tool

Run comprehensive performance benchmarks:

```bash
# Build and run benchmarks
cargo build --release --bin bench
./target/release/bench

# Quick performance check
./target/release/bench --iterations 100

# JSON output for automation
./target/release/bench --format json > results.json
```

### ğŸ” Real-Time Performance Monitoring

Use debug mode to see timing information for your specific templates:

```bash
# Get per-operation timing with debug mode
string-pipeline -d '{split:,:..|map:{upper}|sort}' 'your,data,here'
```

Debug output includes step-by-step timing:

```text
DEBUG: Step completed in 342.7Âµs
DEBUG: Total execution time: 18.7456ms
```

### ğŸš€ Quick Optimization Tips

**Template Performance Best Practices:**

```bash
# âœ… Filter early to reduce data
'{split:,:..|filter:important|map:{expensive_operation}}'

# âœ… Use direct ranges instead of slice
'{split:,:0..10}'

# âœ… Combine operations in single map
'{split:,:..|map:{trim|upper|append:!}}'
```

> ğŸ“Š **Comprehensive Guide:** For detailed benchmarking methodology, performance analysis, automation scripts, and optimization strategies, see the [ğŸ† Performance Benchmarking Guide](benchmarking.md).

## ğŸ”§ Troubleshooting

### ğŸ› Common Issues and Solutions

#### ğŸ” "No Output" Problems

**Problem:** Template runs but produces no output.

```bash
# ğŸ” Diagnose with debug mode
string-pipeline -d '{template}' 'input'

# ğŸ” Check if input is being processed
string-pipeline -d '{upper}' 'test'  # Use a simple template first
```

**Common Causes:**

- Filter operations removing all items
- Range operations selecting empty ranges
- Input not matching expected format

**Solutions:**

```bash
# âœ… Step-by-step debugging
string-pipeline -d '{split:,:..}' 'input'        # Check split result
string-pipeline -d '{split:,:..|filter:pattern}' 'input'  # Check filter
```

#### ğŸ“ File Processing Issues

**Problem:** File input not working as expected.

```bash
# ğŸ” Verify file contents and encoding
file input.txt                    # Check file type
head -5 input.txt                 # Check first few lines
wc -l input.txt                   # Check line count

# ğŸ” Test with simple template first
string-pipeline '{upper}' -f input.txt
```

#### ğŸ”¤ Character Encoding Problems

**Problem:** Special characters not displaying correctly.

```bash
# ğŸ” Check file encoding
file -i input.txt

# ğŸ” Convert if necessary
iconv -f ISO-8859-1 -t UTF-8 input.txt > input_utf8.txt
string-pipeline '{template}' -f input_utf8.txt
```

#### ğŸ”§ Template Complexity Issues

**Problem:** Complex template not working as expected.

```bash
# âœ… Break down complex templates
# Instead of:
string-pipeline '{split:,:..|map:{trim|upper|filter:^[A-Z]{3,}}|sort|unique}'

# Do this:
string-pipeline '{split:,:..}' 'input'                    # Step 1
string-pipeline '{split:,:..|map:{trim}}' 'input'         # Step 2
string-pipeline '{split:,:..|map:{trim|upper}}' 'input'   # Step 3
# ... continue building step by step
```

### ğŸ†˜ Getting Help

1. **ğŸ“– Check Documentation:**
   - Use `--syntax-help` for template syntax
   - Use `--list-operations` for available operations
   - Review template examples in documentation

2. **ğŸ” Enable Debug Mode:**

   ```bash
   string-pipeline -d '{your_template}' 'test_data'
   ```

3. **ğŸ§ª Test with Simple Data:**

   ```bash
   # Test with predictable input
   string-pipeline '{your_template}' 'a,b,c'
   ```

4. **âœ… Validate Templates:**

   ```bash
   string-pipeline --validate '{your_template}'
   ```

---

ğŸ‰ **You're now equipped to master the String Pipeline CLI!**

ğŸ’¡ **Pro Tip:** Combine the power of templates from the [ğŸ“– Template System Documentation](template-system.md) with these CLI features for maximum productivity!

ğŸ› **Debug Like a Pro:** Master the [ğŸ” Debug System Guide](debug-system.md) to troubleshoot complex pipelines and optimize performance!

ğŸš€ **Ready to transform your data processing workflows? Start with simple examples and build up to complex transformations!**
